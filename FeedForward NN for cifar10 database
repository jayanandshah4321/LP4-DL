Build Feedforward neural networks with Keras and TensorFlow for classification of
CIFAR10 image dataset using the following steps:
a. Import the necessary packages
b. Load the training and testing data
c. Define the network architecture using Keras
d. Train the model using SGD/Adam optimizer
e. Evaluate the network
f. Plot the training loss and accuracy

# a. Import the necessary packages
import tensorflow as tf
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import numpy as np

# b. Load the training and testing data
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

print("Training data shape:", x_train.shape)
print("Testing data shape:", x_test.shape)

# -----------------------------------------------
# üîç VISUALIZE SOME IMAGES FROM THE DATASET
# -----------------------------------------------
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10, 5))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.xticks([])  # remove x ticks
    plt.yticks([])  # remove y ticks
    plt.grid(False)
    plt.imshow(x_train[i])  # show image
    plt.xlabel(class_names[int(y_train[i])])  # show label
plt.suptitle("Sample CIFAR-10 Images")
plt.show()

# -----------------------------------------------
# üì¶ Data Preprocessing
# -----------------------------------------------
# Normalize pixel values (0‚Äì255 ‚Üí 0‚Äì1)
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Flatten the images (32x32x3 = 3072 features)
x_train = x_train.reshape(x_train.shape[0], -1)
x_test = x_test.reshape(x_test.shape[0], -1)

# Convert labels to one-hot encoding
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)

# -----------------------------------------------
# c. Define the Feedforward Neural Network
# -----------------------------------------------
model = Sequential()
model.add(Dense(1024, activation='relu', input_shape=(3072,)))
model.add(Dense(512, activation='relu'))
model.add(Dense(256, activation='relu'))
model.add(Dense(10, activation='softmax'))

# -----------------------------------------------
# d. Compile and Train the Model
# -----------------------------------------------
optimizer = Adam(learning_rate=0.001)

model.compile(optimizer=optimizer,
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(x_train, y_train,
                    epochs=10,             # you can change epochs
                    batch_size=128,
                    validation_data=(x_test, y_test),
                    verbose=1)

# -----------------------------------------------
# e. Evaluate the Network
# -----------------------------------------------
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)
print("\nTest Accuracy:", round(test_acc * 100, 2), "%")

# -----------------------------------------------
# f. Plot the Training Loss and Accuracy
# -----------------------------------------------
plt.figure(figsize=(12, 5))

# Accuracy plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy', color='blue')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy', color='orange')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss', color='red')
plt.plot(history.history['val_loss'], label='Validation Loss', color='green')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

